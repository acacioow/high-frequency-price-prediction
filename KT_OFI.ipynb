{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdmfkbb6uoJs",
        "outputId": "3841b11d-5376-4d58-b51b-8d7d1106fb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "The hyperparameter search is complete.\n",
            "\n",
            "The optimal learning rate for the optimizer is 0.001.\n",
            "\n",
            "Best layers units: \n",
            "\n",
            "Layer: 1 , 124 units\n",
            "Layer: 2 , 104 units\n",
            "Layer: 3 , 128 units\n",
            "Layer: 4 , 68 units\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"KT.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/11vdsvxqtHO59DiTM8ufTO-KkgeVK3kAm\n",
        "\"\"\"\n",
        "\n",
        "# Keras-Tuner\n",
        "!pip install -q -U keras-tuner\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# %matplotlib inline\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab import drive\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LSTM, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "import keras_tuner as kt\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/LOBster/MSFT'\n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "df = pd.read_csv(\"data_msft_ta.csv\")\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "X = df[['Price', 'OFI']]\n",
        "y = df['Price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values.reshape(X.shape[0], X.shape[1], 1), y, test_size=0.2, stratify=y, random_state=1234)\n",
        "\n",
        "\n",
        "def model_builder(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=hp.Int('hp_units_1', min_value=4, max_value=128, step=4),\n",
        "                   activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "\n",
        "    for i in range(2, 5):\n",
        "        model.add(Dropout(0.20))\n",
        "        model.add(LSTM(units=hp.Int('hp_units_' + str(i),\n",
        "                                    min_value=4, max_value=128, step=4),\n",
        "                       activation='relu'))\n",
        "\n",
        "    model.add(layers.Dense(units=1, activation='linear'))  # Output layer\n",
        "    # Set the loss function to root mean squared error (RMSE)\n",
        "    loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
        "                  loss=loss, metrics=['mape', tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_mean_squared_error',\n",
        "                     max_epochs=50,\n",
        "                     factor=3,\n",
        "                     directory='KERAS-TUNER',\n",
        "                     project_name='LSTM_PRICE_ONLY')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "tuner.search(X_train, y_train,\n",
        "             batch_size=64,\n",
        "             epochs=50,\n",
        "             validation_split=0.2,\n",
        "             callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete.\n",
        "\n",
        "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "print('Best layers units: \\n')\n",
        "for i in range(2, 6):\n",
        "    print('Layer:', i - 1, ',', best_hps.get('hp_units_' + str(i)), 'units')\n"
      ]
    }
  ]
}